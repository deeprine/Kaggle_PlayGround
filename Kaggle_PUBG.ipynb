{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport gc\nimport os\nimport sys\n\nsns.set_style('darkgrid')\nsns.set_palette('bone')\npd.options.display.float_format = '{:,.3f}'.format\n\nprint(os.listdir('../input/pubg-finish-placement-prediction'))\npubg_path = '../input/pubg-finish-placement-prediction'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(pubg_path + '/train_V2.csv')\ntrain = reduce_mem_usage(train)\ntest = pd.read_csv(pubg_path + '/test_V2.csv')\ntest = reduce_mem_usage(test)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['winPlacePerc'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = train.append(test, sort=False).reset_index(drop = True)\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['HeadAvg'] = all_data['kills'] / all_data['headshotKills']\nall_data['TotalHeals'] = all_data['boosts'] + all_data['heals'] + all_data['revives']\nall_data['Yeopo'] = all_data['kills'] / all_data['killStreaks']\nall_data['Distance'] = all_data['swimDistance'] + all_data['walkDistance'] + all_data['rideDistance']\nall_data['KillContribution'] = all_data['kills']/ all_data['damageDealt']\n\nall_data.drop(['headshotKills','boosts','heals','revives','killStreaks','swimDistance','walkDistance',\n              'rideDistance','damageDealt'], axis = 1, inplace =True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillInf(df, val):\n    numcols = df.select_dtypes(include = 'number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols:\n        df[c].fillna(val, inplace = True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fillInf(all_data,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.loc[all_data['maxPlace'] == 80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = ['HeadAvg','TotalHeals','Yeopo','Distance','KillContribution']\ngroup = all_data.groupby(['matchId','groupId','matchType'])\nmatch = all_data.groupby('matchId')\n\n\nmatch_data = pd.concat([\n    match.size().to_frame('m.players'),\n    match[col].sum().rename(columns = lambda s : 'm.sum.' + s),\n    match[col].max().rename(columns = lambda s : 'm.max.' + s),\n    match[col].mean().rename(columns = lambda s : 'm.mean.' + s)\n], axis = 1).reset_index()    \n\nreduce_mem_usage(match_data)\n\nmatch_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngroup_data = pd.concat([\n    group.size().to_frame('g.player'),\n    group[col].sum().rename(columns = lambda x : 'g.sum.' + x),\n    group[col].max().rename(columns = lambda x : 'g.max.' + x),\n    group[col].mean().rename(columns = lambda x : 'g.mean.' + x)\n], axis = 1).reset_index()\n\nreduce_mem_usage(group_data)\ngroup_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(match_data, group_data)\nfillInf(data, 0)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.merge(all_data, data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['PlayerTime'] = all_data['m.players'] / all_data['matchDuration']\nall_data['enemyPlayer'] = all_data['m.players'] - all_data['g.player']\nall_data['SavePlayer'] = all_data['enemyPlayer'] - all_data['kills']\n\ncols = ['PlayerTime', 'enemyPlayer', 'SavePlayer']\ngroup = all_data.groupby(['matchId','groupId'])\n\ngroup_data = pd.concat([\n    group[cols].mean().rename(columns = lambda x : 'mean.' + x),\n    group[cols].sum().rename(columns = lambda x : 'sum.' + x),\n    \n], axis = 1).reset_index()\n\nall_data = pd.merge(all_data, group_data)\nreduce_mem_usage(all_data)\nall_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.drop(['roadKills','teamKills','vehicleDestroys'], axis = 1, inplace =True)\nidea = all_data[all_data['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis = 1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.get_dummies(all_data, columns = ['matchType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.drop(['Id'], axis =1, inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = all_data[all_data['winPlacePerc'].notnull()].reset_index(drop= True)\n\nX_test = all_data[all_data['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis = 1).reset_index(drop=True)\n\n\ndel all_data\ngc.collect()\n\nY_train = X_train.pop('winPlacePerc')\nX_test_grp = X_test[['matchId','groupId']].copy()\n\nX_train.drop(['matchId','groupId'], axis = 1, inplace = True)\nX_test.drop(['matchId','groupId'], axis = 1, inplace =True)\n\n\nX_train_cols = X_train.columns\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers, regularizers\nfrom keras.callbacks import LearningRateScheduler, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, BatchNormalization, PReLU\nfrom keras.models import load_model\nfrom keras.models import Sequential\n\ndef creatModel():\n    model = Sequential()\n    model.add(Dense(512, kernel_initializer = 'he_normal', input_dim = X_train.shape[1], activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(256, kernel_initializer='he_normal'))\n    model.add(PReLU(alpha_initializer = 'zeros', alpha_regularizer = None, shared_axes = None))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(1, kernel_initializer = 'he_normal'))\n    model.add(PReLU(alpha_initializer = 'zeros', alpha_regularizer=None, shared_axes = None))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.1))\n    \n    optimizer = optimizers.Adam(lr = 0.005)\n    model.compile(optimizer = optimizer, loss='mse', metrics = ['mae'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10, verbose=0):\n    ''' Wrapper function to create a LearningRateScheduler with step decay schedule. '''\n    def schedule(epoch):\n        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n    return LearningRateScheduler(schedule, verbose)\n\nlr_sched = step_decay_schedule(initial_lr=0.001, decay_factor=0.97, step_size=1, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_mean_absolute_error', mode='min', patience=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nnp.random.seed(42)\n\nscaler = preprocessing.StandardScaler().fit(X_train.astype(float))\nX_train = scaler.transform(X_train.astype(float))\nX_test = scaler.transform(X_test.astype(float))\n\n\nmodel = creatModel()\nhistory = model.fit(\n        X_train, Y_train,\n        epochs=200,\n        batch_size=2**15,\n        validation_split=0.2,\n        callbacks=[lr_sched, early_stopping],\n        verbose=2)\npred = model.predict(X_test).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n    'Id' : idea['Id'],\n    'winPlacePerc' : pred\n})\n\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}